{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4873137,"sourceType":"datasetVersion","datasetId":2825527}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The task is based on the Fastai course, which uses the Kaggle competition [U.S. Patent Phrase to Phrase Matching](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/)\n\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:16.731425Z","iopub.execute_input":"2025-08-07T12:42:16.731599Z","iopub.status.idle":"2025-08-07T12:42:17.069687Z","shell.execute_reply.started":"2025-08-07T12:42:16.731583Z","shell.execute_reply":"2025-08-07T12:42:17.068862Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/input/us-patent-phrase-to-phrase-matching/sample_submission.csv\n/kaggle/input/input/us-patent-phrase-to-phrase-matching/train.csv\n/kaggle/input/input/us-patent-phrase-to-phrase-matching/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:17.070445Z","iopub.execute_input":"2025-08-07T12:42:17.070755Z","iopub.status.idle":"2025-08-07T12:42:17.074581Z","shell.execute_reply.started":"2025-08-07T12:42:17.070736Z","shell.execute_reply":"2025-08-07T12:42:17.073666Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from pathlib import Path\npath = Path('/kaggle/input/input/us-patent-phrase-to-phrase-matching')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:17.075558Z","iopub.execute_input":"2025-08-07T12:42:17.076491Z","iopub.status.idle":"2025-08-07T12:42:17.089523Z","shell.execute_reply.started":"2025-08-07T12:42:17.076463Z","shell.execute_reply":"2025-08-07T12:42:17.088662Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Installing Huggingface datasets (if not already present)","metadata":{}},{"cell_type":"code","source":"!pip install -q datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:17.091560Z","iopub.execute_input":"2025-08-07T12:42:17.091776Z","iopub.status.idle":"2025-08-07T12:42:20.448315Z","shell.execute_reply.started":"2025-08-07T12:42:17.091758Z","shell.execute_reply":"2025-08-07T12:42:20.447230Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#Python variables (here 'path') can be included using {} in bash\n!ls {path}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:20.449313Z","iopub.execute_input":"2025-08-07T12:42:20.449543Z","iopub.status.idle":"2025-08-07T12:42:20.573271Z","shell.execute_reply.started":"2025-08-07T12:42:20.449518Z","shell.execute_reply":"2025-08-07T12:42:20.572336Z"}},"outputs":[{"name":"stdout","text":"sample_submission.csv  test.csv  train.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(path/'train.csv')\n#df.head()\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:20.574463Z","iopub.execute_input":"2025-08-07T12:42:20.574699Z","iopub.status.idle":"2025-08-07T12:42:20.648282Z","shell.execute_reply.started":"2025-08-07T12:42:20.574674Z","shell.execute_reply":"2025-08-07T12:42:20.647628Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                     id        anchor                  target context  score\n0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n...                 ...           ...                     ...     ...    ...\n36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n36471  756ec035e694722b  wood article         wooden material     B44   0.75\n36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n\n[36473 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37d61fd2272659b1</td>\n      <td>abatement</td>\n      <td>abatement of pollution</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7b9652b17b68b7a4</td>\n      <td>abatement</td>\n      <td>act of abating</td>\n      <td>A47</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36d72442aefd8232</td>\n      <td>abatement</td>\n      <td>active catalyst</td>\n      <td>A47</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5296b0c19e1ce60e</td>\n      <td>abatement</td>\n      <td>eliminating process</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54c1e3b9184cb5b6</td>\n      <td>abatement</td>\n      <td>forest region</td>\n      <td>A47</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36468</th>\n      <td>8e1386cbefd7f245</td>\n      <td>wood article</td>\n      <td>wooden article</td>\n      <td>B44</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>36469</th>\n      <td>42d9e032d1cd3242</td>\n      <td>wood article</td>\n      <td>wooden box</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>36470</th>\n      <td>208654ccb9e14fa3</td>\n      <td>wood article</td>\n      <td>wooden handle</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>36471</th>\n      <td>756ec035e694722b</td>\n      <td>wood article</td>\n      <td>wooden material</td>\n      <td>B44</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>36472</th>\n      <td>8d135da0b55b8c88</td>\n      <td>wood article</td>\n      <td>wooden substrate</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>36473 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"#\"Generates descriptive statistics that summarize the central tendency, dispersion and shape of a dataset’s distribution, excluding NaN values\"\nprint (df.describe())\nprint ()\nprint (df.describe(include='object'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:20.649050Z","iopub.execute_input":"2025-08-07T12:42:20.649290Z","iopub.status.idle":"2025-08-07T12:42:20.705116Z","shell.execute_reply.started":"2025-08-07T12:42:20.649262Z","shell.execute_reply":"2025-08-07T12:42:20.704568Z"}},"outputs":[{"name":"stdout","text":"              score\ncount  36473.000000\nmean       0.362062\nstd        0.258335\nmin        0.000000\n25%        0.250000\n50%        0.250000\n75%        0.500000\nmax        1.000000\n\n                      id                       anchor       target context\ncount              36473                        36473        36473   36473\nunique             36473                          733        29340     106\ntop     8d135da0b55b8c88  component composite coating  composition     H01\nfreq                   1                          152           24    2186\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#df.input = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor ###--> THis does not add input to df\ndf['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\ndf\n#df.input.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:20.705934Z","iopub.execute_input":"2025-08-07T12:42:20.706219Z","iopub.status.idle":"2025-08-07T12:42:20.735354Z","shell.execute_reply.started":"2025-08-07T12:42:20.706184Z","shell.execute_reply":"2025-08-07T12:42:20.734788Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                     id        anchor                  target context  score  \\\n0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50   \n1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75   \n2      36d72442aefd8232     abatement         active catalyst     A47   0.25   \n3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50   \n4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00   \n...                 ...           ...                     ...     ...    ...   \n36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00   \n36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50   \n36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50   \n36471  756ec035e694722b  wood article         wooden material     B44   0.75   \n36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50   \n\n                                                   input  \n0      TEXT1: A47; TEXT2: abatement of pollution; ANC...  \n1      TEXT1: A47; TEXT2: act of abating; ANC1: abate...  \n2      TEXT1: A47; TEXT2: active catalyst; ANC1: abat...  \n3      TEXT1: A47; TEXT2: eliminating process; ANC1: ...  \n4      TEXT1: A47; TEXT2: forest region; ANC1: abatement  \n...                                                  ...  \n36468  TEXT1: B44; TEXT2: wooden article; ANC1: wood ...  \n36469  TEXT1: B44; TEXT2: wooden box; ANC1: wood article  \n36470  TEXT1: B44; TEXT2: wooden handle; ANC1: wood a...  \n36471  TEXT1: B44; TEXT2: wooden material; ANC1: wood...  \n36472  TEXT1: B44; TEXT2: wooden substrate; ANC1: woo...  \n\n[36473 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n      <th>score</th>\n      <th>input</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37d61fd2272659b1</td>\n      <td>abatement</td>\n      <td>abatement of pollution</td>\n      <td>A47</td>\n      <td>0.50</td>\n      <td>TEXT1: A47; TEXT2: abatement of pollution; ANC...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7b9652b17b68b7a4</td>\n      <td>abatement</td>\n      <td>act of abating</td>\n      <td>A47</td>\n      <td>0.75</td>\n      <td>TEXT1: A47; TEXT2: act of abating; ANC1: abate...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36d72442aefd8232</td>\n      <td>abatement</td>\n      <td>active catalyst</td>\n      <td>A47</td>\n      <td>0.25</td>\n      <td>TEXT1: A47; TEXT2: active catalyst; ANC1: abat...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5296b0c19e1ce60e</td>\n      <td>abatement</td>\n      <td>eliminating process</td>\n      <td>A47</td>\n      <td>0.50</td>\n      <td>TEXT1: A47; TEXT2: eliminating process; ANC1: ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54c1e3b9184cb5b6</td>\n      <td>abatement</td>\n      <td>forest region</td>\n      <td>A47</td>\n      <td>0.00</td>\n      <td>TEXT1: A47; TEXT2: forest region; ANC1: abatement</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36468</th>\n      <td>8e1386cbefd7f245</td>\n      <td>wood article</td>\n      <td>wooden article</td>\n      <td>B44</td>\n      <td>1.00</td>\n      <td>TEXT1: B44; TEXT2: wooden article; ANC1: wood ...</td>\n    </tr>\n    <tr>\n      <th>36469</th>\n      <td>42d9e032d1cd3242</td>\n      <td>wood article</td>\n      <td>wooden box</td>\n      <td>B44</td>\n      <td>0.50</td>\n      <td>TEXT1: B44; TEXT2: wooden box; ANC1: wood article</td>\n    </tr>\n    <tr>\n      <th>36470</th>\n      <td>208654ccb9e14fa3</td>\n      <td>wood article</td>\n      <td>wooden handle</td>\n      <td>B44</td>\n      <td>0.50</td>\n      <td>TEXT1: B44; TEXT2: wooden handle; ANC1: wood a...</td>\n    </tr>\n    <tr>\n      <th>36471</th>\n      <td>756ec035e694722b</td>\n      <td>wood article</td>\n      <td>wooden material</td>\n      <td>B44</td>\n      <td>0.75</td>\n      <td>TEXT1: B44; TEXT2: wooden material; ANC1: wood...</td>\n    </tr>\n    <tr>\n      <th>36472</th>\n      <td>8d135da0b55b8c88</td>\n      <td>wood article</td>\n      <td>wooden substrate</td>\n      <td>B44</td>\n      <td>0.50</td>\n      <td>TEXT1: B44; TEXT2: wooden substrate; ANC1: woo...</td>\n    </tr>\n  </tbody>\n</table>\n<p>36473 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"print(df.columns)\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:20.735976Z","iopub.execute_input":"2025-08-07T12:42:20.736158Z","iopub.status.idle":"2025-08-07T12:42:20.742307Z","shell.execute_reply.started":"2025-08-07T12:42:20.736143Z","shell.execute_reply":"2025-08-07T12:42:20.741550Z"}},"outputs":[{"name":"stdout","text":"Index(['id', 'anchor', 'target', 'context', 'score', 'input'], dtype='object')\n                 id     anchor                  target context  score  \\\n0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n\n                                               input  \n0  TEXT1: A47; TEXT2: abatement of pollution; ANC...  \n1  TEXT1: A47; TEXT2: act of abating; ANC1: abate...  \n2  TEXT1: A47; TEXT2: active catalyst; ANC1: abat...  \n3  TEXT1: A47; TEXT2: eliminating process; ANC1: ...  \n4  TEXT1: A47; TEXT2: forest region; ANC1: abatement  \n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**Tokenization**\n\nThe Tokenization process converts strings to numbers to be used in NN. \n\nHuggingface's transformer object **Dataset** stores the input dataset.\n\n\"**Transformers** acts as the model-definition framework for state-of-the-art machine learning models in text, computer vision, audio, video, and multimodal models, for both inference and training.\" (https://huggingface.co/docs/transformers/en/index)","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset,DatasetDict\n\nds = Dataset.from_pandas(df)\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:20.743167Z","iopub.execute_input":"2025-08-07T12:42:20.743837Z","iopub.status.idle":"2025-08-07T12:42:21.278136Z","shell.execute_reply.started":"2025-08-07T12:42:20.743794Z","shell.execute_reply":"2025-08-07T12:42:21.277436Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n    num_rows: 36473\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"Two steps are involved\n\n*Tokenization*: Split each text up into words (popularly, subwords are used, as here) as tokens.\n\n*Numericalization*: Convert each word (or token) into a number.\n\nDifferent Huggingface models(transformers) can be found here: https://huggingface.co/models","metadata":{}},{"cell_type":"code","source":"model_nm = 'microsoft/deberta-v3-small'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:21.279078Z","iopub.execute_input":"2025-08-07T12:42:21.279518Z","iopub.status.idle":"2025-08-07T12:42:21.282929Z","shell.execute_reply.started":"2025-08-07T12:42:21.279490Z","shell.execute_reply":"2025-08-07T12:42:21.282275Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"*AutoTokenizer* will create a tokenizer appropriate for a given pretrained model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification,AutoTokenizer\ntokz = AutoTokenizer.from_pretrained(model_nm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:21.283634Z","iopub.execute_input":"2025-08-07T12:42:21.283901Z","iopub.status.idle":"2025-08-07T12:42:26.911835Z","shell.execute_reply.started":"2025-08-07T12:42:21.283877Z","shell.execute_reply":"2025-08-07T12:42:26.911040Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"An example of tokenizing a sentence. Further details on the process can be followed from the book \"Deep Learning for Coders with Fastai and PyTorch\" Chapter-10","metadata":{}},{"cell_type":"code","source":"tokz.tokenize(\"Checking if it is working properly.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:26.914695Z","iopub.execute_input":"2025-08-07T12:42:26.915116Z","iopub.status.idle":"2025-08-07T12:42:26.920736Z","shell.execute_reply.started":"2025-08-07T12:42:26.915097Z","shell.execute_reply":"2025-08-07T12:42:26.920199Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['▁Checking', '▁if', '▁it', '▁is', '▁working', '▁properly', '.']"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"#Tokenizing the inputs from ds; x is a document and x['input'] is the section we are willing to tokenize\n#'ds.map' parallelize the process\n\ndef tok_func(x): return tokz(x[\"input\"])\n\ntok_ds = ds.map(tok_func, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:26.921553Z","iopub.execute_input":"2025-08-07T12:42:26.922108Z","iopub.status.idle":"2025-08-07T12:42:28.524650Z","shell.execute_reply.started":"2025-08-07T12:42:26.922081Z","shell.execute_reply":"2025-08-07T12:42:28.523850Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/36473 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c737fa1280ca447bb1ea0cffdd489961"}},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"*input_ids* is added to the dataset","metadata":{}},{"cell_type":"code","source":"print (tok_ds)\nprint ('First row')\ntok_ds[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.525544Z","iopub.execute_input":"2025-08-07T12:42:28.525732Z","iopub.status.idle":"2025-08-07T12:42:28.532700Z","shell.execute_reply.started":"2025-08-07T12:42:28.525717Z","shell.execute_reply":"2025-08-07T12:42:28.531871Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['id', 'anchor', 'target', 'context', 'score', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 36473\n})\nFirst row\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'id': '37d61fd2272659b1',\n 'anchor': 'abatement',\n 'target': 'abatement of pollution',\n 'context': 'A47',\n 'score': 0.5,\n 'input': 'TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement',\n 'input_ids': [1,\n  54453,\n  435,\n  294,\n  336,\n  5753,\n  346,\n  54453,\n  445,\n  294,\n  47284,\n  265,\n  6435,\n  346,\n  23702,\n  435,\n  294,\n  47284,\n  2],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"row = tok_ds[0]\nrow['input'], row['input_ids']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.533725Z","iopub.execute_input":"2025-08-07T12:42:28.534283Z","iopub.status.idle":"2025-08-07T12:42:28.550149Z","shell.execute_reply.started":"2025-08-07T12:42:28.534265Z","shell.execute_reply":"2025-08-07T12:42:28.549289Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"('TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement',\n [1,\n  54453,\n  435,\n  294,\n  336,\n  5753,\n  346,\n  54453,\n  445,\n  294,\n  47284,\n  265,\n  6435,\n  346,\n  23702,\n  435,\n  294,\n  47284,\n  2])"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"tokz.tokenize(\"TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.550946Z","iopub.execute_input":"2025-08-07T12:42:28.551225Z","iopub.status.idle":"2025-08-07T12:42:28.566408Z","shell.execute_reply.started":"2025-08-07T12:42:28.551201Z","shell.execute_reply":"2025-08-07T12:42:28.565540Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['▁TEXT',\n '1',\n ':',\n '▁A',\n '47',\n ';',\n '▁TEXT',\n '2',\n ':',\n '▁abatement',\n '▁of',\n '▁pollution',\n ';',\n '▁ANC',\n '1',\n ':',\n '▁abatement']"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"#To be noted, it's not a simple _\ntokz.vocab['▁of'], tokz.vocab['▁TEXT']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.567452Z","iopub.execute_input":"2025-08-07T12:42:28.567839Z","iopub.status.idle":"2025-08-07T12:42:28.761764Z","shell.execute_reply.started":"2025-08-07T12:42:28.567787Z","shell.execute_reply":"2025-08-07T12:42:28.760947Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(265, 54453)"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"Preparing labels: By default, *Transformers* uses the column name *labels* for targets, currently it is named as *score*. So need to rename it.","metadata":{}},{"cell_type":"code","source":"tok_ds = tok_ds.rename_columns({'score':'labels'})  #Can be run only once, can't be renamed twice\ntok_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.762692Z","iopub.execute_input":"2025-08-07T12:42:28.762983Z","iopub.status.idle":"2025-08-07T12:42:28.774676Z","shell.execute_reply.started":"2025-08-07T12:42:28.762958Z","shell.execute_reply":"2025-08-07T12:42:28.773852Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 36473\n})"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"tok_ds[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.775424Z","iopub.execute_input":"2025-08-07T12:42:28.775690Z","iopub.status.idle":"2025-08-07T12:42:28.785837Z","shell.execute_reply.started":"2025-08-07T12:42:28.775668Z","shell.execute_reply":"2025-08-07T12:42:28.784997Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'id': '37d61fd2272659b1',\n 'anchor': 'abatement',\n 'target': 'abatement of pollution',\n 'context': 'A47',\n 'labels': 0.5,\n 'input': 'TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement',\n 'input_ids': [1,\n  54453,\n  435,\n  294,\n  336,\n  5753,\n  346,\n  54453,\n  445,\n  294,\n  47284,\n  265,\n  6435,\n  346,\n  23702,\n  435,\n  294,\n  47284,\n  2],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"**Creating a validation set**","metadata":{}},{"cell_type":"markdown","source":"Higgingface creates training and validation sets using *train_test_split* and holds them in *DatasetDict* ","metadata":{}},{"cell_type":"code","source":"dds = tok_ds.train_test_split(0.25, seed=42)\ndds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.786652Z","iopub.execute_input":"2025-08-07T12:42:28.786970Z","iopub.status.idle":"2025-08-07T12:42:28.809257Z","shell.execute_reply.started":"2025-08-07T12:42:28.786953Z","shell.execute_reply":"2025-08-07T12:42:28.808552Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 27354\n    })\n    test: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9119\n    })\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"**Test Set**","metadata":{}},{"cell_type":"code","source":"eval_df = pd.read_csv(path/'test.csv')\neval_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.809972Z","iopub.execute_input":"2025-08-07T12:42:28.810157Z","iopub.status.idle":"2025-08-07T12:42:28.825758Z","shell.execute_reply.started":"2025-08-07T12:42:28.810143Z","shell.execute_reply":"2025-08-07T12:42:28.825233Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                      id          anchor                         target  \\\ncount                 36              36                             36   \nunique                36              34                             36   \ntop     4112d61851461f60  hybrid bearing  inorganic photoconductor drum   \nfreq                   1               2                              1   \n\n       context  \ncount       36  \nunique      29  \ntop        G02  \nfreq         3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>36</td>\n      <td>34</td>\n      <td>36</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>4112d61851461f60</td>\n      <td>hybrid bearing</td>\n      <td>inorganic photoconductor drum</td>\n      <td>G02</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"eval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\neval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.826472Z","iopub.execute_input":"2025-08-07T12:42:28.826673Z","iopub.status.idle":"2025-08-07T12:42:28.872080Z","shell.execute_reply.started":"2025-08-07T12:42:28.826657Z","shell.execute_reply":"2025-08-07T12:42:28.871331Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/36 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b61fd472b381458d94ccb7522cba351c"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"#from sklearn.linear_model import LinearRegression\n#from sklearn.preprocessing import PolynomialFeatures\n#from sklearn.pipeline import make_pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.872745Z","iopub.execute_input":"2025-08-07T12:42:28.873089Z","iopub.status.idle":"2025-08-07T12:42:28.876153Z","shell.execute_reply.started":"2025-08-07T12:42:28.873072Z","shell.execute_reply":"2025-08-07T12:42:28.875476Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"*np.corrcoef* presents all the (Pearson) correlation coefficients for every combination of columns in a dataset and generates a correlation coefficient matrix","metadata":{}},{"cell_type":"code","source":"def corr(x,y): return np.corrcoef(x,y)[0][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.876752Z","iopub.execute_input":"2025-08-07T12:42:28.877021Z","iopub.status.idle":"2025-08-07T12:42:28.886432Z","shell.execute_reply.started":"2025-08-07T12:42:28.876996Z","shell.execute_reply":"2025-08-07T12:42:28.885792Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"Huggingface expects a dict, where it (trainer) uses the keys of the dict to label the matric. Here labelled as 'pearson'","metadata":{}},{"cell_type":"code","source":"def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.887073Z","iopub.execute_input":"2025-08-07T12:42:28.887235Z","iopub.status.idle":"2025-08-07T12:42:28.896275Z","shell.execute_reply.started":"2025-08-07T12:42:28.887222Z","shell.execute_reply":"2025-08-07T12:42:28.895680Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"The validity of the model is measured with a metric (not same as loss function), here: 'Pearson coefficient' is used ","metadata":{}},{"cell_type":"markdown","source":"**Training our model**","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments,Trainer\nbs = 128   #Batch size\nepochs = 5\nlr = 8e-5  #Learning rate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:28.896971Z","iopub.execute_input":"2025-08-07T12:42:28.897163Z","iopub.status.idle":"2025-08-07T12:42:33.832141Z","shell.execute_reply.started":"2025-08-07T12:42:28.897149Z","shell.execute_reply":"2025-08-07T12:42:33.831424Z"}},"outputs":[{"name":"stderr","text":"2025-08-07 12:42:31.119464: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754570551.142687    1365 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754570551.150246    1365 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"*output_dir='outputs'* : Specifies the directory where the model checkpoints and training logs will be saved ('outputs')\n\n\n*learning_rate=lr* : Sets the learning rate for the optimizer. \n\n\n*warmup_ratio=0.1* : Specifies the ratio of total training steps used for a linear warmup from 0 to the initial learning rate. Warmup helps in stabilizing the training process at the beginning.\n\n\n*lr_scheduler_type='cosine'* : Defines the type of learning rate scheduler to use. A 'cosine' scheduler adjusts the learning rate following a cosine curve, which can help in fine-tuning the model by reducing the learning rate gradually.\n\n\n*fp16=True* : Enables mixed-precision training using 16-bit floating-point numbers. This can speed up training and reduce memory usage on compatible hardware (like modern GPUs).\n\n\n*eval_strategy=\"epoch\"* : Determines when to evaluate the model during training. Setting it to \"epoch\" means the model will be evaluated at the end of each epoch.\n\n\n*per_device_train_batch_size=bs* : Sets the batch size for training on each device (e.g., GPU). \n\n\n*per_device_eval_batch_size* : Sets the batch size for evaluation on each device. It is set to twice the training batch size to speed up the evaluation process\n\n\n*num_train_epochs=epochs* : Specifies the total number of training epochs. \n\n\n*weight_decay=0.01* : Applies weight decay (L2 regularization) to the model weights. This helps in preventing overfitting by penalizing large weights.\n\n\n*report_to='none'* : Disables logging to external tools like TensorBoard, Weights & Biases, etc. Setting it to 'none' means no training logs will be sent to these tools.","metadata":{}},{"cell_type":"code","source":"args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    eval_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:33.833017Z","iopub.execute_input":"2025-08-07T12:42:33.833577Z","iopub.status.idle":"2025-08-07T12:42:33.868575Z","shell.execute_reply.started":"2025-08-07T12:42:33.833547Z","shell.execute_reply":"2025-08-07T12:42:33.867746Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"'AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)': uses the pretrained model (model_nm) and retrieves the appropriate model architecture for sequence classification. *num_labels=1* defines a single output label, meaning the model is set up for a regression task or binary classification.\n\n'Trainer()' handles the training and evaluation loop of the model. *tokenizer=tokz* defines the tokenizer to be used for preprocessing the text data. *compute_metrics=corr_d* defines the function (Pearson coefficient) that computes evaluation metrics during training. ","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                  tokenizer=tokz, compute_metrics=corr_d)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:33.869597Z","iopub.execute_input":"2025-08-07T12:42:33.869847Z","iopub.status.idle":"2025-08-07T12:42:35.042317Z","shell.execute_reply.started":"2025-08-07T12:42:33.869800Z","shell.execute_reply":"2025-08-07T12:42:35.041744Z"}},"outputs":[{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_1365/3597993663.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"trainer.train();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:42:44.810133Z","iopub.execute_input":"2025-08-07T12:42:44.810742Z","iopub.status.idle":"2025-08-07T12:48:58.324381Z","shell.execute_reply.started":"2025-08-07T12:42:44.810720Z","shell.execute_reply":"2025-08-07T12:48:58.323534Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='535' max='535' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [535/535 06:11, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.031425</td>\n      <td>0.770882</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.031110</td>\n      <td>0.807556</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.022745</td>\n      <td>0.822505</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.023277</td>\n      <td>0.829488</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.030700</td>\n      <td>0.023717</td>\n      <td>0.831113</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"preds = trainer.predict(eval_ds).predictions.astype(float)\npreds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:49:05.062124Z","iopub.execute_input":"2025-08-07T12:49:05.062422Z","iopub.status.idle":"2025-08-07T12:49:05.219303Z","shell.execute_reply.started":"2025-08-07T12:49:05.062402Z","shell.execute_reply":"2025-08-07T12:49:05.218542Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"array([[ 0.55440444],\n       [ 0.67733246],\n       [ 0.59256715],\n       [ 0.390297  ],\n       [-0.01822404],\n       [ 0.61738127],\n       [ 0.52325743],\n       [ 0.0042911 ],\n       [ 0.28748569],\n       [ 1.0962193 ],\n       [ 0.25615668],\n       [ 0.2429643 ],\n       [ 0.7715897 ],\n       [ 0.99523842],\n       [ 0.77812153],\n       [ 0.45243955],\n       [ 0.26934263],\n       [-0.03151863],\n       [ 0.63524711],\n       [ 0.42111173],\n       [ 0.43756419],\n       [ 0.31096733],\n       [ 0.1983379 ],\n       [ 0.25154191],\n       [ 0.60437584],\n       [-0.03200336],\n       [-0.01799715],\n       [-0.03605735],\n       [-0.0435862 ],\n       [ 0.63208884],\n       [ 0.30731422],\n       [ 0.04474068],\n       [ 0.68221527],\n       [ 0.49376798],\n       [ 0.43906361],\n       [ 0.19034836]])"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"preds = np.clip(preds, 0, 1)\npreds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T12:49:12.204666Z","iopub.execute_input":"2025-08-07T12:49:12.205211Z","iopub.status.idle":"2025-08-07T12:49:12.210603Z","shell.execute_reply.started":"2025-08-07T12:49:12.205187Z","shell.execute_reply":"2025-08-07T12:49:12.210048Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([[0.55440444],\n       [0.67733246],\n       [0.59256715],\n       [0.390297  ],\n       [0.        ],\n       [0.61738127],\n       [0.52325743],\n       [0.0042911 ],\n       [0.28748569],\n       [1.        ],\n       [0.25615668],\n       [0.2429643 ],\n       [0.7715897 ],\n       [0.99523842],\n       [0.77812153],\n       [0.45243955],\n       [0.26934263],\n       [0.        ],\n       [0.63524711],\n       [0.42111173],\n       [0.43756419],\n       [0.31096733],\n       [0.1983379 ],\n       [0.25154191],\n       [0.60437584],\n       [0.        ],\n       [0.        ],\n       [0.        ],\n       [0.        ],\n       [0.63208884],\n       [0.30731422],\n       [0.04474068],\n       [0.68221527],\n       [0.49376798],\n       [0.43906361],\n       [0.19034836]])"},"metadata":{}}],"execution_count":32}]}
